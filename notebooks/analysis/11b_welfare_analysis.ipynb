{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welfare Analysis\n",
    "Summarise distribution of welfare of different groups, under different sampling schemes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# from src.utils.helper_funcs import find_project_root\n",
    "\n",
    "# PROJECT_ROOT = find_project_root()\n",
    "# DATA_DIR = PROJECT_ROOT / 'data'\n",
    "DATA_DIR = \"../../data/\"\n",
    "RES_DIR = \"../../results/welfare/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "utterances_path = DATA_DIR + \"utterances.jsonl\"\n",
    "survey_path = DATA_DIR + \"survey.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data\n",
    "utterances = pd.read_json(utterances_path, lines=True)\n",
    "survey = pd.read_json(survey_path, lines=True)\n",
    "\n",
    "### clean data\n",
    "# Unnest survey data\n",
    "\n",
    "nested_columns = [\n",
    "    \"location\",\n",
    "    \"religion\",\n",
    "    \"ethnicity\",\n",
    "    \"order_lm_usecases\",\n",
    "    \"order_stated_prefs\",\n",
    "]\n",
    "# Normalize each column and join back to the original DataFrame\n",
    "for col in nested_columns:\n",
    "    df_expanded = pd.json_normalize(survey[col])\n",
    "    df_expanded.columns = [\n",
    "        f\"{col}_{subcol}\" for subcol in df_expanded.columns\n",
    "    ]  # Prefixing column names\n",
    "    survey = survey.join(df_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean utterances\n",
    "utterances[\"short_model_name\"] = utterances[\"model_name\"].apply(\n",
    "    lambda x: x.split(\"/\")[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "Keys varibles are: gender, age, birth_country_region, lm_categorised_ethnicity, score and normalised_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##merged dataset of utterances\n",
    "\n",
    "merged = utterances.merge(survey, on=\"user_id\", how=\"left\")\n",
    "merged = merged[\n",
    "    (merged[\"turn\"] == 0) & (merged[\"included_in_balanced_subset_x\"] == True)\n",
    "]  # & (merged['included_in_balanced_subset'] == True)] #only keep first interaction\n",
    "models = merged[\"short_model_name\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate veto: if score less than 10, veto\n",
    "merged[\"veto\"] = merged[\"score\"].apply(lambda x: 1 if x <= 10 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute scores with matrix factorisation\n",
    "\n",
    "Do we impute user average scores, or interaction scores? think more about this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate sampling dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate sampling dictionary\n",
    "\n",
    "sampling_dict = {\n",
    "    # non country demographics\n",
    "    \"white_male\": survey[\n",
    "        (survey[\"gender\"] == \"Male\") & (survey[\"ethnicity_simplified\"] == \"White\")\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"male\": survey[(survey[\"gender\"] == \"Male\")][\"user_id\"].tolist(),\n",
    "    \"nonmale\": survey[(survey[\"gender\"] != \"Male\")][\"user_id\"].tolist(),\n",
    "    \"white\": survey[(survey[\"ethnicity_simplified\"] == \"White\")][\"user_id\"].tolist(),\n",
    "    \"above_45\": survey[\n",
    "        (survey[\"age\"].isin([\"45-54 years old\", \"55-64 years old\", \"65+ years old\"]))\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"all\": survey[\"user_id\"].tolist(),\n",
    "    # us breakdown\n",
    "    \"us_white\": survey[\n",
    "        (survey[\"included_in_US_REP\"] == True)\n",
    "        & (survey[\"ethnicity_simplified\"] == \"White\")\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"us_nonwhite\": survey[\n",
    "        (survey[\"included_in_US_REP\"] == True)\n",
    "        & (survey[\"ethnicity_simplified\"] != \"White\")\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"us_male\": survey[\n",
    "        (survey[\"included_in_US_REP\"] == True) & (survey[\"gender\"] == \"Male\")\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"us_nonmale\": survey[\n",
    "        (survey[\"included_in_US_REP\"] == True) & (survey[\"gender\"] != \"Male\")\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"us_above_45\": survey[\n",
    "        (survey[\"included_in_US_REP\"] == True)\n",
    "        & (survey[\"age\"].isin([\"45-54 years old\", \"55-64 years old\", \"65+ years old\"]))\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"us_below_45\": survey[\n",
    "        (survey[\"included_in_US_REP\"] == True)\n",
    "        & (\n",
    "            survey[\"age\"].isin([\"45-54 years old\", \"55-64 years old\", \"65+ years old\"])\n",
    "            == False\n",
    "        )\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"us\": survey[(survey[\"included_in_US_REP\"] == True)][\"user_id\"].tolist(),\n",
    "    # uk breakdown\n",
    "    \"uk_white\": survey[\n",
    "        (survey[\"included_in_UK_REP\"] == True)\n",
    "        & (survey[\"ethnicity_simplified\"] == \"White\")\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"uk_nonwhite\": survey[\n",
    "        (survey[\"included_in_UK_REP\"] == True)\n",
    "        & (survey[\"ethnicity_simplified\"] != \"White\")\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"uk_male\": survey[\n",
    "        (survey[\"included_in_UK_REP\"] == True) & (survey[\"gender\"] == \"Male\")\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"uk_nonmale\": survey[\n",
    "        (survey[\"included_in_UK_REP\"] == True) & (survey[\"gender\"] != \"Male\")\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"uk_above_45\": survey[\n",
    "        (survey[\"included_in_UK_REP\"] == True)\n",
    "        & (survey[\"age\"].isin([\"45-54 years old\", \"55-64 years old\", \"65+ years old\"]))\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"uk_below_45\": survey[\n",
    "        (survey[\"included_in_UK_REP\"] == True)\n",
    "        & (\n",
    "            survey[\"age\"].isin([\"45-54 years old\", \"55-64 years old\", \"65+ years old\"])\n",
    "            == False\n",
    "        )\n",
    "    ][\"user_id\"].tolist(),\n",
    "    \"uk\": survey[(survey[\"included_in_UK_REP\"] == True)][\"user_id\"].tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) welfare table\n",
    "\n",
    "Given distribution, compute distribution of welfare (rating on approach response)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welfare table for scores\n",
    "welfare_table = pd.pivot_table(\n",
    "    merged,\n",
    "    values=\"score\",\n",
    "    index=\"user_id\",\n",
    "    columns=\"short_model_name\",\n",
    "    aggfunc=\"mean\",\n",
    "    fill_value=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welfare table for choices\n",
    "choice_table = pd.pivot_table(\n",
    "    merged,\n",
    "    values=\"if_chosen\",\n",
    "    index=\"user_id\",\n",
    "    columns=\"short_model_name\",\n",
    "    aggfunc=\"mean\",\n",
    "    fill_value=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welfare table for vetos - 1 if user gives score below 10\n",
    "veto_table = pd.pivot_table(\n",
    "    merged,\n",
    "    values=\"veto\",\n",
    "    index=\"user_id\",\n",
    "    columns=\"short_model_name\",\n",
    "    aggfunc=\"mean\",\n",
    "    fill_value=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) functions for generating model selection empirical distributions\n",
    "\n",
    "First, we will select models based on mean (normalised) score.\n",
    "\n",
    "Next, we will select models based on pairwise battles. Winner can be chosen by multiple social choice rules i.e. elo, rank centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_distribution(\n",
    "    sample_size,\n",
    "    sampling_pool_ids,\n",
    "    emp_dist_gran=100,\n",
    "    method=\"max_mean_rating\",\n",
    "    welfare_table_=welfare_table,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate empirical sampling distribution of models chosen. We weight all individuals in rater_sample evenly - for example, if one rater rates a model twice,\n",
    "      and another rates it once, take the average rating of each rater for that model.\n",
    "    Args,\n",
    "        sameple_size (int): sample size\n",
    "        sampling_pool_ids (list): list of ids to sample from (with replacement)\n",
    "        emp_dist_gran (int): granularity of the empirical distribution\n",
    "    Returns,\n",
    "        Empirical sampling distribution of models chosen, given sampling scheme\n",
    "    \"\"\"\n",
    "\n",
    "    model_dist = [\"t\"] * emp_dist_gran  # model empirical distribution\n",
    "    for j in range(emp_dist_gran):\n",
    "        # initalise candidate models\n",
    "        scores = [-1] * len(models)\n",
    "        rater_sample = random.choices(sampling_pool_ids, k=sample_size)\n",
    "\n",
    "        filtered_data = welfare_table_.reindex(rater_sample)\n",
    "        # loop through candidate models\n",
    "        if method == \"max_mean_rating\":  # pick model with highest rating\n",
    "            for i in range(len(models)):\n",
    "                sample_scores = filtered_data[models[i]]\n",
    "                if np.isnan(sample_scores).all():\n",
    "                    scores[i] = 1\n",
    "                else:\n",
    "                    scores[i] = np.nanmean(sample_scores)\n",
    "\n",
    "        elif method == \"max_pc_chosen\":  # pick model with highest choice rate\n",
    "            for i in range(len(models)):\n",
    "                sample_scores = filtered_data[models[i]]\n",
    "                if np.isnan(sample_scores).all():\n",
    "                    scores[i] = 0\n",
    "                else:\n",
    "                    scores[i] = np.nanmean(sample_scores)\n",
    "\n",
    "        elif method == \"min_pc_veto\":  # pick model with minimum veto\n",
    "            for i in range(len(models)):\n",
    "                sample_scores = filtered_data[models[i]]\n",
    "                if np.isnan(sample_scores).all():\n",
    "                    scores[i] = 1  # or handle it in another appropriate wa\n",
    "                else:\n",
    "                    scores[i] = 1 - np.nanmean(sample_scores)\n",
    "        else:\n",
    "            print(\n",
    "                \"error - please select one method from: max_normalised_rating, max_pc_chosen,min_pc_veto\"\n",
    "            )\n",
    "\n",
    "        # pick winning model\n",
    "        max_indices = [\n",
    "            index for index, value in enumerate(scores) if value >= max(scores)\n",
    "        ]  # find argmax\n",
    "        if len(max_indices) == 0:  # if all na, pick random\n",
    "            winner_index = random.choice([index for index, value in enumerate(scores)])\n",
    "        else:  # random pick out of winners\n",
    "            winner_index = random.choice(max_indices)\n",
    "        # add to list\n",
    "        model_dist[j] = models[winner_index]\n",
    "\n",
    "    return model_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_welfare_df_full(\n",
    "    population,\n",
    "    welfare_metric_table=welfare_table,\n",
    "    model_choice_rule=\"max_mean_rating\",\n",
    "    country=\"us\",\n",
    "    emp_dist_gran_=100,\n",
    "):\n",
    "    dict_res = {}\n",
    "    # df_res_temp = pd.DataFrame(columns = ['sampling_scheme','mean_social_welfare','percentile_5','percentile_25','percentile_75','percentile_95'])\n",
    "    welfare_table_temp = welfare_metric_table.reindex(sampling_dict[population])\n",
    "    # loop through sample sizes\n",
    "    for n in [10, 20, 50, 100]:\n",
    "        dist_temp = [\n",
    "            welfare_table_temp[i_].mean()\n",
    "            for i_ in gen_model_distribution(\n",
    "                n,\n",
    "                sampling_dict[country],\n",
    "                emp_dist_gran=emp_dist_gran_,\n",
    "                method=model_choice_rule,\n",
    "                welfare_table_=welfare_metric_table,\n",
    "            )\n",
    "        ]\n",
    "        sampling_scheme = country + \"_rep_\" + str(n)\n",
    "        dict_res[sampling_scheme] = dist_temp\n",
    "\n",
    "    for scheme in [country + i_ for i_ in [\"_male\", \"_white\", \"_above_45\"]]:\n",
    "        dist_temp = [\n",
    "            welfare_table_temp[i__].mean()\n",
    "            for i__ in gen_model_distribution(\n",
    "                100,\n",
    "                sampling_dict[scheme],\n",
    "                emp_dist_gran=emp_dist_gran_,\n",
    "                method=model_choice_rule,\n",
    "                welfare_table_=welfare_metric_table,\n",
    "            )\n",
    "        ]\n",
    "        sampling_scheme = scheme + \"_100\"\n",
    "        dict_res[sampling_scheme] = dist_temp\n",
    "\n",
    "    return dict_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving us\n",
      "saving us_nonmale\n",
      "saving us_nonwhite\n",
      "saving us_below_45\n",
      "saving uk\n",
      "saving uk_nonmale\n",
      "saving uk_nonwhite\n",
      "saving uk_below_45\n",
      "saving us\n",
      "saving us_nonmale\n",
      "saving us_nonwhite\n",
      "saving us_below_45\n",
      "saving uk\n",
      "saving uk_nonmale\n",
      "saving uk_nonwhite\n",
      "saving uk_below_45\n"
     ]
    }
   ],
   "source": [
    "n_emp_dist_gran = 1000\n",
    "random.seed(1)\n",
    "\n",
    "# rating data\n",
    "for c in [\"us\", \"uk\"]:\n",
    "    for s in [\"\", \"nonmale\", \"nonwhite\", \"below_45\"]:\n",
    "        if s == \"\":\n",
    "            pop = c\n",
    "        else:\n",
    "            pop = c + \"_\" + s\n",
    "        output_dict = gen_welfare_df_full(\n",
    "            population=pop, country=c, emp_dist_gran_=n_emp_dist_gran\n",
    "        )\n",
    "        print(\"saving \" + pop)\n",
    "        with open(RES_DIR + \"welfare_\" + pop + \"_rating.pickle\", \"wb\") as file:\n",
    "            pickle.dump(output_dict, file)\n",
    "\n",
    "\n",
    "# choice data\n",
    "for c in [\"us\", \"uk\"]:\n",
    "    for s in [\"\", \"nonmale\", \"nonwhite\", \"below_45\"]:\n",
    "        if s == \"\":\n",
    "            pop = c\n",
    "        else:\n",
    "            pop = c + \"_\" + s\n",
    "        output_dict = gen_welfare_df_full(\n",
    "            population=pop,\n",
    "            country=c,\n",
    "            emp_dist_gran_=n_emp_dist_gran,\n",
    "            welfare_metric_table=choice_table,\n",
    "            model_choice_rule=\"max_pc_chosen\",\n",
    "        )\n",
    "        print(\"saving \" + pop)\n",
    "        with open(RES_DIR + \"welfare_\" + pop + \"_choice.pickle\", \"wb\") as file:\n",
    "            pickle.dump(output_dict, file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a894b0d91aa6fdb901c32194035570c2587ca737a18661c5a772d280489dfd59"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
